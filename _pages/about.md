---
permalink: /
title: "Juncheng Ma"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# Short Bio 
Hi! I am a junior undergraduate at <a href='https://www.ucas.ac.cn/index.htm'>University of Chinese Academy of Sciences</a> . Previously, I explored audio-visual learning as a visiting student in <a href='https://gewu-lab.github.io/'>GeWu-Lab</a>, supervised by Prof. <a href='https://dtaoo.github.io/'>Di Hu</a>.

I am currently interning at <a href='https://www.shlab.org.cn/'>Shanghai AI Laboratory</a>, focusing on video generation. I am excited to explore audio-driven image animation, supervised by Dr. Yanan Sun and Dr. <a href='https://zengyh1900.github.io/'>Yanhong Zeng</a>.

My research interest primarily includes Video Generation/Understanding, Mutilmodal Learning and AI for Science.

# ğŸ”¥ News
- *2024.07*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by <a href='https://eccv2024.ecva.net/'>ECCV2024</a>.


# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='images/teaser.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Stepping Stones: A Progressive Training Strategy for Audio-Visual Semantic Segmentation](https://arxiv.org/abs/2407.11820)

**Juncheng Ma**, Peiwen Sun, Yaoting Wang, Di Hu

<span style="color:red">**ECCV 2024**</span> \| [**arXiv**](https://arxiv.org/abs/2407.11820) \| [**Code**](https://github.com/GeWu-Lab/Stepping-Stones) \| [**Project**](https://gewu-lab.github.io/stepping_stones/) \| [**PDF**](pdfs/09290.pdf) \| [**Supplementary**](pdfs/09290-supp.pdf)

Rethink audio-visual semantic segmentatoin from a new perspective, with a progressive two-stage training strategy proposed to enhance the capability of <span style="color:red">audio-visual alignment</span> .
</div>
</div>

# ğŸ’» Experiences
<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge"></div><img src='images/pjlab.png' alt="sym" style="display: inline-block; width: 80%;"></div></div>
<div class='paper-box-text' markdown="1">

**Research Intern, Shanghai AI Laboratory, Shanghai, China, 2024.7-present**

Research on video generation especially audio-driven image animation.

Supervised by Dr. Yanan Sun and Dr. <a href='https://zengyh1900.github.io/'>Yanhong Zeng</a>

</div>
</div>
<div class='paper-box'><div class='paper-box-image' style="text-align: center;"><div><div class="badge"></div><img src='images/ruc.png' alt="sym" style="display: inline-block; width: 80%;"></div></div>
<div class='paper-box-text' markdown="1">

**Visiting Student, Renmin University of China, Beijing, China, 2023.10-2024.3**

Research on multimodal learning especially audio-visual segmentation, aiming to segment sound sources within a video according to its corresponding audio. 

One paper [*Stepping-Stones*](https://gewu-lab.github.io/stepping_stones/) is accepted by ECCV2024.

Supervised by Prof. <a href='https://dtaoo.github.io/'>Di Hu</a>

</div>
</div>


# ğŸ“– Educations
- *2021.09 - present*, Undergraduate, University of Chinese Academy of Sciences. 
